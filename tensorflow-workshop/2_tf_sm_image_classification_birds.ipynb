{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow with Amazon SageMaker's training and hosting services\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Train the model](#Train-the-model)\n",
    "4. [Host the model](#Host-the-model)\n",
    "5. [Test the model](#Test-the-model)\n",
    "6. [Clean up](#Clean-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The previous lab performed training and prediction directly in the Jupyter notebook environment. With this lab, we transition to leveraging SageMaker's managed training and hosting services. To accomplish this, we use [Amazon SageMaker's TensorFlow container](https://sagemaker.readthedocs.io/en/stable/using_tf.html), which lets you provide your training code as a Python script. The container also provides a flexible way for you to customize how inference inputs and outputs are handled over a REST interface. Here is a [blog post](https://aws.amazon.com/blogs/machine-learning/using-tensorflow-eager-execution-with-amazon-sagemaker-script-mode/) describing how TensorFlow eager execution is supported by the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before preparing the data, there are some initial steps required for setup. To train the image classification algorithm on Amazon SageMaker, we need to setup and authenticate the use of AWS services. To begin with, we need an AWS account role with SageMaker access. Here we will use the execution role the current notebook instance was given when it was created.  This role has necessary permissions, including access to your data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to identify the S3 bucket that you want to use for providing training and validation datasets.  It will  be used to store the tranied model artifacts as well. In this notebook, we use a default bucket for use with SageMaker in your account. Alternatively, you could use whatever bucket you would like.  We use an object prefix to help organize the bucket content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sess.default_bucket() # or use your own custom bucket name\n",
    "prefix = 'DEMO-TF2-image-classification-birds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook assumes you have already downloaded and unpacked the dataset into your notebook instance as part of the first lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters for the rest of the notebook to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a few parameters that help drive the rest of the notebook.  For example, `SAMPLE_ONLY` is defaulted to `True`. This will force the notebook to train on only a handful of species.  Setting `SAMPLE_ONLY` to false will make the notebook work with the entire dataset of 200 bird species.  This makes the training a more difficult challenge, and you will need to tune parameters and run more epochs.\n",
    "\n",
    "An `EXCLUDE_IMAGE_LIST` is defined as a mechanism to address any corrupt images from the dataset and ensure they do not disrupt the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "runtime = boto3.client(service_name='runtime.sagemaker')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# To speed up training and experimenting, you can use a small handful of species.\n",
    "# To see the full list of the classes available, look at the content of CLASSES_FILE.\n",
    "SAMPLE_ONLY = True\n",
    "\n",
    "if SAMPLE_ONLY:\n",
    "    CLASSES = [13, 17] #, 35, 36, 47, 68, 73, 75, 87, 95, 120, 179, 192]\n",
    "else:\n",
    "    # Otherwise, you can use the full set of species\n",
    "    CLASSES = []\n",
    "    for c in range(200):\n",
    "        CLASSES += [c + 1]\n",
    "    prefix = prefix + '-full'\n",
    "\n",
    "BASE_DIR     = 'CUB_MINI/' # 'CUB_200_2011/' if using the full download\n",
    "IMAGES_DIR   = BASE_DIR + 'images/'\n",
    "CLASSES_FILE = BASE_DIR + 'classes.txt'\n",
    "\n",
    "EXCLUDE_IMAGE_LIST = ['087.Mallard/Mallard_0130_76836.jpg']\n",
    "\n",
    "SPLIT_RATIOS = (0.6, 0.2, 0.2)\n",
    "\n",
    "CLASS_COLS      = ['class_number','class_id']\n",
    "\n",
    "JOB_PREFIX     = 'tf2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the list of bird species or dataset classes the model will be trained to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(CLASSES_FILE, sep=' ', names=CLASS_COLS, header=None)\n",
    "criteria = classes_df['class_number'].isin(CLASSES)\n",
    "classes_df = classes_df[criteria]\n",
    "\n",
    "class_name_list = sorted(classes_df['class_id'].unique().tolist())\n",
    "print(class_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/val/test dataframes from our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we've moved the train/test split logic to a utilities script to keep the focus of the notebook on the actual training and hosting steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import split\n",
    "train_df, val_df, test_df = split.get_train_val_dataframes(BASE_DIR, CLASSES, EXCLUDE_IMAGE_LIST, SPLIT_RATIOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data channels for Amazon SageMaker\n",
    "When using Amazon SageMaker's managed training service, you need to provide the datasets to the training algorithm. This is primarily handled via populating S3 buckets, and by indicating the location of data channels such as train, test, and validation. You also need to consider the data format. In our case, to keep things simple, we will populate the data channels with folders containing the original JPG images organized by class folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate local data channels\n",
    "Here we populate the local channel folders, and we handle re-populating in case we have already run through this notebook with a different subset of bird species. The local content will be synchronized to our s3 bucket for access by the SageMaker training service. Note that if you are running this notebook with a large number of bird species, this step could take several minutes. You can skip these cells if you are re-running this notebook after already having populated these folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def copy_files_for_channel(df, channel_name, verbose=False):\n",
    "    print('\\nCopying files for {} images in channel: {}...'.format(df.shape[0], channel_name))\n",
    "    for i in range(df.shape[0]):\n",
    "        target_fname = df.iloc[i]['image_file_name']\n",
    "        if verbose:\n",
    "            print(target_fname)\n",
    "        src = f'{cwd}/{IMAGES_DIR}/{target_fname}'\n",
    "        dst = f'{cwd}/{CHANNEL_FOLDER}/{channel_name}/{target_fname}'\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(CHANNEL_FOLDER):\n",
    "    print('About to remove {}/{}'.format(cwd, CHANNEL_FOLDER))\n",
    "    perform_delete = input('Are you sure you want to remove it and start fresh (yes/no)?')\n",
    "    if perform_delete == 'yes':\n",
    "        for ch in ['train', 'test', 'validation']:\n",
    "            !rm -i -rf $CHANNEL_FOLDER/$ch/*\n",
    "            !rm -i -rf $CHANNEL_FOLDER/$ch\n",
    "            !mkdir  $CHANNEL_FOLDER/$ch\n",
    "\n",
    "        for c in class_name_list:\n",
    "            !mkdir $CHANNEL_FOLDER/train/$c\n",
    "            !mkdir $CHANNEL_FOLDER/validation/$c\n",
    "            !mkdir $CHANNEL_FOLDER/test/$c\n",
    "            \n",
    "        copy_files_for_channel(val_df,   'validation')\n",
    "        copy_files_for_channel(test_df,  'test')\n",
    "        copy_files_for_channel(train_df, 'train')\n",
    "else:\n",
    "    print('Channel folder does not yet exist. Creating it and subfolders for each channel.')\n",
    "    os.mkdir(CHANNEL_FOLDER)\n",
    "    os.mkdir(CHANNEL_FOLDER + '/validation')\n",
    "    os.mkdir(CHANNEL_FOLDER + '/test')\n",
    "    os.mkdir(CHANNEL_FOLDER + '/train')\n",
    "    for c in class_name_list:\n",
    "        os.mkdir('{}/{}/{}'.format(CHANNEL_FOLDER, 'validation', c))\n",
    "        os.mkdir('{}/{}/{}'.format(CHANNEL_FOLDER, 'test', c))\n",
    "        os.mkdir('{}/{}/{}'.format(CHANNEL_FOLDER, 'train', c))\n",
    "    \n",
    "    copy_files_for_channel(val_df,   'validation')\n",
    "    copy_files_for_channel(test_df,  'test')\n",
    "    copy_files_for_channel(train_df, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload content of each data channel to S3\n",
    "Note that for local mode training, this copy to s3 is not necessary. SageMaker local mode is helpful for early iterations of the development of a new model. Once the approach is more stable, you typically then use SageMaker training jobs on larger sets of data and with additional epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('About to uploaded your image data to s3://{}/{}'.format(bucket, prefix))\n",
    "print('This will ensure you have the latest data for training, but it takes a while if using the full 200 classes.')\n",
    "if input('Are you sure you want to replace your s3 images?') == 'yes':\n",
    "    print('Clearing out s3://{}/{}/'.format(bucket, prefix))\n",
    "    for ch in ['train', 'test', 'validation']:\n",
    "        !aws s3 rm --quiet --recursive s3://$bucket/$prefix/$ch/\n",
    "    print('\\nSynchronizing local data channels with s3...')\n",
    "    !aws s3 sync $CHANNEL_FOLDER s3://$bucket/$prefix/\n",
    "\n",
    "print('contents of s3://{}/{}/'.format(bucket, prefix))\n",
    "!aws s3 ls s3://$bucket/$prefix/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model \n",
    "When using [SageMaker's TensorFlow container](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html), the custom TensorFlow training code is provided via a Python script in a separate file that gets passed to SageMaker. For our example, that script is shown below for completeness in the notebook. Study that code before proceeding to the actual training. Pay attention to any differences from the code you used in the first lab when training directly in the notebook:\n",
    "\n",
    "- Use of script parameters to make the code more flexible. We will take advantage of these parameters later on when doing automatic model tuning.\n",
    "- Copying of `inference.py` and `requirements.txt` to the `code` directory for use with TensorFlow Serving at inference time.\n",
    "- Different approach to model saving to be compatible with TensorFlow Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pygmentize 'code/train-mobilenet.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about customizing your SageMaker hosted TensorFlow endpoint\n",
    "For our example, we need some preprocessing code to take the raw image bytes and prepare the image for being passed to the image classification model. To do so, we provide an `inference.py` script with an `input_handler()` function. See the [documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#create-python-scripts-for-custom-input-and-output-formats) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train in local mode, it is necessary to have Docker Compose or NVIDIA-Docker-Compose (for GPU) installed in the notebook instance.  This simple setup script is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SageMaker training job using the TensorFlow container\n",
    "Here we establish the Tensorflow estimator object. Note that this notebook code is designed to support SageMaker remote training jobs as well as local mode training. Set `local = False` to use SageMaker's training service on separate managed training instances. Metric definitions are provided so that you can visualize metrics from the SageMaker console as well as from CloudWatch. These same metrics can be used when optimizing your model with automatic model tuning.\n",
    "\n",
    "For this lab, run the whole notebook with `local = True` first. Once you have understood all that is going on, and have seen it work successfully, change to `local = False` and re-run the rest of the notebook.\n",
    "\n",
    "### A note about instance types and account limits\n",
    "You may find yourself running into an error like this:\n",
    "\n",
    "````\n",
    "ResourceLimitExceeded: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.p3.8xlarge for training job usage' is 0 Instances, with current utilization of 0 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.\n",
    "````\n",
    "To avoid customers getting unexpected bills for more powerful and more expensive instance usage, accounts are established by default with limited access to certain instance types. These are soft limits that can be raised by contacting AWS support. This lab defaults to a powerful GPU instance type, but you can run it on a lower-powered instance type. In such a case, you will pay less, but your training jobs will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about TensorFlow versions\n",
    "Amazon SageMaker supports multiple versions of TensorFlow natively. In addition, you can bring your own container if you have specific requirements that are not met by [SageMaker's TensorFlow container](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html). When instantiating a TensorFlow estimator object, you specify a TensorFlow framework version. This directs SageMaker to find the corresponding container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "TF_FRAMEWORK_VERSION = '2.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `requirements.txt` file lists the set of Python packages that will be pip installed in your endpoint before calling your `input_handler` from your `inference.py` script. If you are using TensorFlow specific code, be sure to include the `tensorflow` package. These packages will also be installed when using SageMaker batch transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./code/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about spot training\n",
    "When using SageMaker's Managed Spot Training, the SageMaker TensorFlow container handles checkpointing for you as long as you pass in an S3 location for the checkpoints. If your spot instance gets taken away, the training will automatically resume from the last saved checkpoint without any manual intervention. Here we specify a unique location for those checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "checkpoint_s3_uri = f's3://{bucket}/{prefix}/checkpoints/{uuid.uuid4()}'\n",
    "print(checkpoint_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a SageMaker TensorFlow estimator. You can use it in local mode or use it to run managed training jobs on separate training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = True\n",
    "if (local):\n",
    "    train_instance_type  = 'local'\n",
    "    train_instance_count = 1\n",
    "    serve_instance_type  = 'local'\n",
    "    initial_epochs       = 3\n",
    "    fine_tuning_epochs   = 5\n",
    "    use_spot             = False\n",
    "else:\n",
    "    train_instance_type  = 'ml.c5.4xlarge' #'ml.p2.xlarge' #'ml.p3.2xlarge' \n",
    "    train_instance_count = 1\n",
    "    serve_instance_type  = 'ml.c5.4xlarge'\n",
    "    use_spot             = True\n",
    "    if SAMPLE_ONLY:\n",
    "        initial_epochs     = 5\n",
    "        fine_tuning_epochs = 20\n",
    "    else:\n",
    "        initial_epochs     = 10\n",
    "        fine_tuning_epochs = 300\n",
    "\n",
    "hyperparameters = {'initial_epochs':     initial_epochs,\n",
    "                   'batch_size':         8,\n",
    "                   'fine_tuning_epochs': fine_tuning_epochs, \n",
    "                   'dropout':            0.4,\n",
    "                   'data_dir':           '/opt/ml/input/data'}\n",
    "if use_spot:\n",
    "    hyperparameters['s3_checkpoint_path'] = checkpoint_s3_uri\n",
    "\n",
    "# TF changed the logging of accuracy metrics in TF 2.x (from 'acc' to 'accuracy').\n",
    "if TF_FRAMEWORK_VERSION[0] == '2':\n",
    "    metric_definitions=[{'Name' : 'validation:acc', \n",
    "                         'Regex': '.*step.* - val_accuracy: (.*$)'},\n",
    "                        {'Name' : 'validation:loss', \n",
    "                         'Regex': '- val_loss: (.*?) '},\n",
    "                        {'Name' : 'acc', \n",
    "                         'Regex': '.*step.* - accuracy: (.*?) '},\n",
    "                        {'Name' : 'loss', \n",
    "                         'Regex': '.*step.* - loss: (.*?) '}]\n",
    "else:\n",
    "    metric_definitions=[{'Name' : 'validation:acc', \n",
    "                         'Regex': '.*step.* - val_acc: (.*$)'},\n",
    "                        {'Name' : 'validation:loss', \n",
    "                         'Regex': '- val_loss: (.*?) '},\n",
    "                        {'Name' : 'acc', \n",
    "                         'Regex': '.*step.* - acc: (.*?) '},\n",
    "                        {'Name' : 'loss', \n",
    "                         'Regex': '.*step.* - loss: (.*?) '}]\n",
    "\n",
    "if train_instance_count > 1:\n",
    "    distributions = {'parameter_server': {'enabled': True}}\n",
    "else:\n",
    "    distributions = {'parameter_server': {'enabled': False}}\n",
    "\n",
    "if use_spot:\n",
    "    estimator = TensorFlow(entry_point='train-mobilenet.py',\n",
    "                           source_dir='code',\n",
    "                           train_instance_type=train_instance_type,\n",
    "                           train_instance_count=train_instance_count,\n",
    "                           distributions=distributions,\n",
    "                           hyperparameters=hyperparameters,\n",
    "                           metric_definitions=metric_definitions,\n",
    "                           role=sagemaker.get_execution_role(),\n",
    "                           train_use_spot_instances=use_spot,\n",
    "                           train_max_run=60*60*10,\n",
    "                           train_max_wait=60*60*12, # Seconds to wait for spot instances to become available\n",
    "                           checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "                           framework_version=TF_FRAMEWORK_VERSION, \n",
    "                           py_version='py3',\n",
    "                           base_job_name=JOB_PREFIX,\n",
    "                           script_mode=True)\n",
    "else:\n",
    "    estimator = TensorFlow(entry_point='train-mobilenet.py',\n",
    "                           source_dir='code',\n",
    "                           train_instance_type=train_instance_type,\n",
    "                           train_instance_count=train_instance_count,\n",
    "                           distributions=distributions,\n",
    "                           hyperparameters=hyperparameters,\n",
    "                           metric_definitions=metric_definitions,\n",
    "                           role=sagemaker.get_execution_role(),\n",
    "                           framework_version=TF_FRAMEWORK_VERSION, \n",
    "                           py_version='py3',\n",
    "                           base_job_name=JOB_PREFIX,\n",
    "                           script_mode=True)\n",
    "\n",
    "### To experiment with the use of Spot instances for SageMaker training, add this set of parameters to your\n",
    "## call above when creating the TensorFlow estimator object:\n",
    "##\n",
    "######    train_use_spot_instances=True, train_max_run=2*60*60, train_max_wait=3*60*60,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we establish pointers to where each data channel is located. For local mode training, these will be in the local file system. For remote training, the s3 data channel copies are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "print('Local data dir: {}'.format(data_dir))\n",
    "\n",
    "if (local):\n",
    "    train_in = f'file://{data_dir}/train'\n",
    "    test_in  = f'file://{data_dir}/test'\n",
    "    val_in   = f'file://{data_dir}/validation'\n",
    "else:\n",
    "    s3_base  = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "    if train_instance_count > 1:\n",
    "        DISTRIBUTION_MODE = 'ShardedByS3Key'\n",
    "    else:\n",
    "        DISTRIBUTION_MODE = 'FullyReplicated'\n",
    "        \n",
    "    train_in = sagemaker.s3_input(s3_data=f'{s3_base}/train', distribution=DISTRIBUTION_MODE)\n",
    "    test_in  = sagemaker.s3_input(s3_data=f'{s3_base}/test',  distribution=DISTRIBUTION_MODE)\n",
    "    val_in   = sagemaker.s3_input(s3_data=f'{s3_base}/validation', distribution=DISTRIBUTION_MODE)\n",
    "\n",
    "inputs = {'train':train_in, 'test': test_in, 'validation': val_in}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tell the estimator to fit the model. For local mode, this training is performed in the current notebook instance. For remote training, new instances are launched and training is performed on those separate instances. No matter which technique you use, the training script can count on the same interface (script parameters, specific SageMaker environment variables, consistent location of data channels in `/opt/ml/input/data`, and saving to `/opt/ml/model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch lab will ask you to provide the name of the training job that produced the resulting model artifacts. The model will be used for batch inference in that lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Completed training job: {}'.format(estimator.latest_training_job.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about spot\n",
    "If you want to try simulating managed spot recovery from prior checkpoints, uncomment this block of code.\n",
    "We'll bump up the number of epochs by 10, but pass in the checkpoint_s3_uri from the prior job. The job\n",
    "should find the checkpoints from the prior training job, resume training from the final checkpoint of the prior job, and run for an additional 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = {'initial_epochs': initial_epochs,\n",
    "#                    'batch_size': 8,\n",
    "#                    'fine_tuning_epochs': fine_tuning_epochs + 10, \n",
    "#                    'dropout': 0.4,\n",
    "#                    'data_dir': '/opt/ml/input/data',\n",
    "#                    's3_checkpoint_path': checkpoint_s3_uri}\n",
    "# estimator = TensorFlow(entry_point='train-mobilenet.py',\n",
    "#                        source_dir='code',\n",
    "#                        train_instance_type=train_instance_type,\n",
    "#                        train_instance_count=train_instance_count,\n",
    "#                        distributions=distributions,\n",
    "#                        hyperparameters=hyperparameters,\n",
    "#                        metric_definitions=metric_definitions,\n",
    "#                        role=sagemaker.get_execution_role(),\n",
    "#                        train_use_spot_instances=use_spot,\n",
    "#                        train_max_run=60*60*10,\n",
    "#                        train_max_wait=60*60*12, # Seconds to wait for spot instances to become available\n",
    "#                        checkpoint_s3_uri=checkpoint_s3_uri,  # add when using spot\n",
    "#                        framework_version=TF_FRAMEWORK_VERSION, \n",
    "#                        py_version='py3',\n",
    "#                        base_job_name=JOB_PREFIX,\n",
    "#                        script_mode=True)\n",
    "# estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the fit method is complete, we can simply call deploy (`estimator.deploy(...)`) to publish the trained model. \n",
    "\n",
    "### A note about iterating on your inference script\n",
    "There are some scenarios in which you want to train once, but deploy multiple times with different iterations of your `inference.py` script. You can avoid having to retrain the model by simply replacing the `inference.py` file in the model artifacts compressed zip file. \n",
    "\n",
    "This next cell runs a script that downloads the model artifacts, replaces the inference files, and uploads the new model artifacts zip for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not local:\n",
    "    # re-deploy model with new inference.py without having to re-do training job\n",
    "    training_job_name = estimator.latest_training_job.name\n",
    "    model_artifacts = 's3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name)\n",
    "    print(model_artifacts)\n",
    "\n",
    "    !bash ./replace-inference.sh $model_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deploy the model to a SageMaker endpoint.\n",
    "\n",
    "If iterating on changes to your `inference.py` script, we re-create the SageMaker model object with the latest version of your script and deploy the endpoint using this latest model. This avoids having to run a new training job (`estimator.fit(inputs)`) just to grab your latest script copy.\n",
    "\n",
    "Otherwise, simply deploy the model directly from the original estimator. You can use this approach (`estimator.deploy()`) once your `inference.py` code is stable. The deploy method will automatically create a SageMaker Model object on your behalf before creating your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "if not local:\n",
    "    model = Model(model_data=model_artifacts, \n",
    "                  role=sagemaker.get_execution_role(),\n",
    "                  framework_version=TF_FRAMEWORK_VERSION,\n",
    "                  sagemaker_session=sess)\n",
    "    predictor = model.deploy(initial_instance_count=1, \n",
    "                            instance_type=serve_instance_type)\n",
    "else:\n",
    "    predictor = estimator.deploy(initial_instance_count=1, \n",
    "                               instance_type=serve_instance_type,\n",
    "                               endpoint_type='tensorflow-serving') # endpoint_type parameter required for TFS local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note about attaching a predictor to an already running endpoint\n",
    "If you are using an endpoint that was already in service, without an estimator object, you can establish a predictor object using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker import RealTimePredictor\n",
    "#predictor = RealTimePredictor(endpoint='<put-endpoint-name-here>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting using the SageMaker TensorFlow endpoint\n",
    "When calling your image classifier hosted in a SageMaker endpoint, the call to the predictor is slightly different than what you used in the first lab:\n",
    "\n",
    "1. In lab 1, we preprocessed the image bytes, which is specific to our base MobileNet model. Instead, here we pass the image bytes directly. This hides the implementation detail of a model-specific preprocessing of the image as part of the endpoint. This gives us flexibility to switch to a different implementation down the road (e.g., ResNet50, InceptionV3, ...).\n",
    "2. We indicate the content type for the REST call, in this case `application/x-image`.\n",
    "3. The results come back as a json document, with the actual predictions in a `predictions` object.\n",
    "\n",
    "The rest of the code remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT=224; WIDTH=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer\n",
    "from IPython.display import Image, display\n",
    "from numpy import argmax\n",
    "\n",
    "def predict_bird_from_file(fn, verbose=True):\n",
    "    with open(fn, 'rb') as img:\n",
    "        f = img.read()\n",
    "    x = bytearray(f)\n",
    "    \n",
    "    predictor.content_type = 'application/x-image'\n",
    "    predictor.deserializer = json_deserializer\n",
    "    predictor.serializer   = None\n",
    "    \n",
    "    results = predictor.predict(x)['predictions']\n",
    "\n",
    "    predicted_class_idx = argmax(results)\n",
    "    predicted_class = class_name_list[predicted_class_idx]\n",
    "    confidence = results[0][predicted_class_idx]\n",
    "    if verbose:\n",
    "        display(Image(fn, height=HEIGHT, width=WIDTH))\n",
    "        print('Class: {}, confidence: {:.2f}'.format(predicted_class, confidence))\n",
    "    del img, x\n",
    "    return predicted_class_idx, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bird_from_file('northern-cardinal-2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.GnBu):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), \n",
    "                                  range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_xticklabels(class_name_list)\n",
    "    plt.gca().set_yticklabels(class_name_list)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def create_and_plot_confusion_matrix(actual, predicted):\n",
    "    cnf_matrix = confusion_matrix(actual, np.asarray(predicted),labels=range(len(class_name_list)))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=range(len(class_name_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess prediction performance against validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Iterate through entire dataframe, tracking predictions and accuracy. For mistakes, show the image, and the predicted and actual classes to help understand\n",
    "# where the model may need additional tuning.\n",
    "\n",
    "def test_image_df(df):\n",
    "    print('Testing {} images'.format(df.shape[0]))\n",
    "    num_errors = 0\n",
    "    preds = []\n",
    "    acts  = []\n",
    "    for i in range(df.shape[0]):\n",
    "        fname = df.iloc[i]['image_file_name']\n",
    "        act   = int(df.iloc[i]['class_id']) - 1\n",
    "        acts.append(act)\n",
    "        pred, conf = predict_bird_from_file(IMAGES_DIR + '/' + fname, verbose=False)\n",
    "        preds.append(pred)\n",
    "        if (pred != act):\n",
    "            num_errors += 1\n",
    "            print('ERROR on image index {} -- Pred: {} {:.2f}, Actual: {}'.format(i, \n",
    "                                                                   class_name_list[pred], conf, \n",
    "                                                                   class_name_list[act]))\n",
    "            img = Image(filename=f'{IMAGES_DIR}/{fname}', width=WIDTH, height=HEIGHT)\n",
    "            display(img)\n",
    "\n",
    "    return num_errors, preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = val_df.shape[0]\n",
    "num_errors, preds, acts = test_image_df(val_df)\n",
    "print('\\nAccuracy: {:.2f}, {}/{}'.format(1 - (num_errors/num_images), num_images - num_errors, num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_confusion_matrix(acts, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = test_df.shape[0]\n",
    "num_errors, preds, acts = test_image_df(test_df)\n",
    "print('\\nAccuracy: {:.2f}, {}/{}'.format(1 - (num_errors/num_images), num_images - num_errors, num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_confusion_matrix(acts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model against previously unseen images\n",
    "Here we download images that the algorithm has not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bird_from_file('northern-cardinal-2.jpg')\n",
    "predict_bird_from_file('bobolink.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Finally, and importantly, to avoid being billed for an idle endpoint, here we delete the SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
